{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hTNPGTckGsI"
      },
      "source": [
        "## Task: 02\n",
        "\n",
        "The goal of this task is to implement **Gradient Descent** algorithm in Python. Gradient Descent dictates how the weights get updated from an inital value to ensure we reach a minimal loss value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ee9xrZVikGsL"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc84dSmkkGsN"
      },
      "source": [
        "Let us make use of a randomly-created sample dataset as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U-Qc1pHokGsO"
      },
      "outputs": [],
      "source": [
        "#sample-dataset\n",
        "x_data = [1.0, 2.0, 3.0]\n",
        "y_data = [2.0, 4.0, 6.0]\n",
        "\n",
        "# Let us initialize our weight value (w) with 1.0\n",
        "w = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLR0__DKkGsO"
      },
      "source": [
        "## Task: 02 - a\n",
        "Implement the forward and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#forward function to calculate y_pred for a given x according to the linear model defined above\n",
        "def forward(w, x):\n",
        "    #implement the forward model to compute y_pred as w*x\n",
        "    ## YOUR CODE STARTS HERE\n",
        "    return w*x\n",
        "\n",
        "    ## YOUR CODE ENDS HERE\n",
        "\n",
        "#loss-function to compute the mean-squared error between y_pred and y_actual\n",
        "def loss(y_pred, y_actual):\n",
        "    #calculate the mean-squared-error between y_pred and y_actual\n",
        "    ## YOUR CODE STARTS HERE\n",
        "    return (y_pred - y_actual)**2\n",
        "\n",
        "    ## YOUR CODE ENDS HERE"
      ],
      "metadata": {
        "id": "3tBly4znk_ij"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UFyg4XwkGsQ"
      },
      "source": [
        "### Gradient Descent\n",
        "\n",
        "We update the `w` such that loss is minimum. The factor by which `w` is updated each time is called `alpha(learning rate)`.\n",
        "\n",
        "New `w` is `w` minus `alpha` times derivative of `loss` against `w`, which can be mathematically expressed as follows:\n",
        "\n",
        "$w=w-\\alpha*\\frac{d(loss)}{dw}$\n",
        "\n",
        "This equation is dependent on how the loss function has been defined. \n",
        "In the current case below formula will dictate how to update the value of w for each pass. \n",
        "\n",
        "$w = w - \\alpha*(2x)*(y_{pred}-y_{actual})$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z13cuySvkGsR"
      },
      "source": [
        "## Task: 02 - b\n",
        "Complete the gradient function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d2nA6eyCkGsS"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the gradient for w to be updated and get min loss.\n",
        "# Gradient = derivative of the loss for constant x and y with respect to the weight w\n",
        "\n",
        "def gradient(x, y, w):\n",
        "    #implement the gradient of loss with respect to the weight (w)\n",
        "    ## YOUR CODE STARTS HERE\n",
        "    y_pred = forward(w, x)\n",
        "    return 2*x*(y_pred - y)\n",
        "\n",
        "    ## YOUR CODE ENDS HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhOnXD7skGsT"
      },
      "source": [
        "Calculate $y_{pred}$ for $x=4$ without training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IfGx_H5MkGsT"
      },
      "outputs": [],
      "source": [
        "y_pred_without_train = forward(w, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geQNFG45kGsU"
      },
      "source": [
        "Begin Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Go10fqsMkGsU",
        "outputId": "011ea914-7397-4e4b-88b8-15b75a18d0af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress:  0 w= 1.260688 loss= 4.0525143466666655\n",
            "Progress:  1 w= 1.453417766656 loss= 2.2150323422596667\n",
            "Progress:  2 w= 1.5959051959019805 loss= 1.2106973245614812\n",
            "Progress:  3 w= 1.701247862192685 loss= 0.6617456475624202\n",
            "Progress:  4 w= 1.7791289594933983 loss= 0.36169841395033914\n",
            "Progress:  5 w= 1.836707389300983 loss= 0.19769792689395907\n",
            "Progress:  6 w= 1.8792758133988885 loss= 0.1080581744091792\n",
            "Progress:  7 w= 1.910747160155559 loss= 0.05906267829964466\n",
            "Progress:  8 w= 1.9340143044689266 loss= 0.03228261061229798\n",
            "Progress:  9 w= 1.9512159834655312 loss= 0.01764510140664452\n",
            "Progress:  10 w= 1.9639333911678687 loss= 0.00964449893442513\n",
            "Progress:  11 w= 1.9733355232910992 loss= 0.005271511767061955\n",
            "Progress:  12 w= 1.9802866323953892 loss= 0.0028813146747399157\n",
            "Progress:  13 w= 1.9854256707695 loss= 0.0015748754098861908\n",
            "Progress:  14 w= 1.9892250235079405 loss= 0.0008607989187741338\n",
            "Progress:  15 w= 1.9920339305797026 loss= 0.000470497395483675\n",
            "Progress:  16 w= 1.994110589284741 loss= 0.0002571655172060062\n",
            "Progress:  17 w= 1.9956458879852805 loss= 0.0001405621027335221\n",
            "Progress:  18 w= 1.9967809527381737 loss= 7.68287480356221e-05\n",
            "Progress:  19 w= 1.9976201197307648 loss= 4.199322868633153e-05\n",
            "Progress:  20 w= 1.998240525958391 loss= 2.295275272069943e-05\n",
            "Progress:  21 w= 1.99869919972735 loss= 1.2545566843471576e-05\n",
            "Progress:  22 w= 1.9990383027488265 loss= 6.857183943871714e-06\n",
            "Progress:  23 w= 1.9992890056818404 loss= 3.7480149144916997e-06\n",
            "Progress:  24 w= 1.999474353368653 loss= 2.0485983625691286e-06\n",
            "Progress:  25 w= 1.9996113831376856 loss= 1.1197274682384291e-06\n",
            "Progress:  26 w= 1.9997126908902887 loss= 6.120231403258154e-07\n",
            "Progress:  27 w= 1.9997875889274812 loss= 3.345209748970213e-07\n",
            "Progress:  28 w= 1.9998429619451539 loss= 1.8284322155969052e-07\n",
            "Progress:  29 w= 1.9998838998815958 loss= 9.993885639181628e-08\n",
            "Progress:  30 w= 1.9999141657892625 loss= 5.462480332433112e-08\n",
            "Progress:  31 w= 1.9999365417379913 loss= 2.9856946996895115e-08\n",
            "Progress:  32 w= 1.9999530845453979 loss= 1.6319276770280646e-08\n",
            "Progress:  33 w= 1.9999653148414271 loss= 8.919826743712008e-09\n",
            "Progress:  34 w= 1.999974356846045 loss= 4.875418822697411e-09\n",
            "Progress:  35 w= 1.9999810417085633 loss= 2.664817308553861e-09\n",
            "Progress:  36 w= 1.9999859839076413 loss= 1.4565417959819284e-09\n",
            "Progress:  37 w= 1.9999896377347262 loss= 7.961198678232563e-10\n",
            "Progress:  38 w= 1.999992339052936 loss= 4.3514497534261613e-10\n",
            "Progress:  39 w= 1.9999943361699042 loss= 2.3784251245645866e-10\n",
            "Progress:  40 w= 1.9999958126624442 loss= 1.3000049163724156e-10\n",
            "Progress:  41 w= 1.999996904251097 loss= 7.105595905649731e-11\n",
            "Progress:  42 w= 1.999997711275687 loss= 3.8837924790431617e-11\n",
            "Progress:  43 w= 1.9999983079186507 loss= 2.1228119672861727e-11\n",
            "Progress:  44 w= 1.9999987490239537 loss= 1.1602913056989068e-11\n",
            "Progress:  45 w= 1.9999990751383971 loss= 6.3419461313939024e-12\n",
            "Progress:  46 w= 1.9999993162387186 loss= 3.4663950822524747e-12\n",
            "Progress:  47 w= 1.9999994944870796 loss= 1.8946699647269e-12\n",
            "Progress:  48 w= 1.9999996262682318 loss= 1.0355929406354807e-12\n",
            "Progress:  49 w= 1.999999723695619 loss= 5.660367024448634e-13\n",
            "Progress:  50 w= 1.9999997957248556 loss= 3.0938560464107196e-13\n",
            "Progress:  51 w= 1.9999998489769344 loss= 1.691046745512068e-13\n",
            "Progress:  52 w= 1.9999998883468353 loss= 9.242961093241007e-14\n",
            "Progress:  53 w= 1.9999999174534755 loss= 5.052038309321895e-14\n",
            "Progress:  54 w= 1.999999938972364 loss= 2.7613543938978922e-14\n",
            "Progress:  55 w= 1.9999999548815364 loss= 1.509307240699509e-14\n",
            "Progress:  56 w= 1.9999999666433785 loss= 8.24960519393613e-15\n",
            "Progress:  57 w= 1.9999999753390494 loss= 4.509087636292239e-15\n",
            "Progress:  58 w= 1.9999999817678633 loss= 2.4645871936597784e-15\n",
            "Progress:  59 w= 1.9999999865207625 loss= 1.3470995683872634e-15\n",
            "Progress:  60 w= 1.999999990034638 loss= 7.363006925426945e-16\n",
            "Progress:  61 w= 1.9999999926324883 loss= 4.0244888963833234e-16\n",
            "Progress:  62 w= 1.99999999455311 loss= 2.1997141494645185e-16\n",
            "Progress:  63 w= 1.9999999959730488 loss= 1.2023247480972207e-16\n",
            "Progress:  64 w= 1.9999999970228268 loss= 6.57169288724515e-17\n",
            "Progress:  65 w= 1.9999999977989402 loss= 3.5919704877484956e-17\n",
            "Progress:  66 w= 1.9999999983727301 loss= 1.9633069604482358e-17\n",
            "Progress:  67 w= 1.9999999987969397 loss= 1.0731089361601375e-17\n",
            "Progress:  68 w= 1.999999999110563 loss= 5.865424223592648e-18\n",
            "Progress:  69 w= 1.9999999993424284 loss= 3.20593709572895e-18\n",
            "Progress:  70 w= 1.9999999995138495 loss= 1.7523084712433846e-18\n",
            "Progress:  71 w= 1.9999999996405833 loss= 9.577798640455507e-19\n",
            "Progress:  72 w= 1.999999999734279 loss= 5.235054256286194e-19\n",
            "Progress:  73 w= 1.9999999998035491 loss= 2.8613885224338016e-19\n",
            "Progress:  74 w= 1.9999999998547615 loss= 1.563982536494851e-19\n",
            "Progress:  75 w= 1.9999999998926234 loss= 8.548468207419028e-20\n",
            "Progress:  76 w= 1.9999999999206153 loss= 4.672426679712873e-20\n",
            "Progress:  77 w= 1.9999999999413098 loss= 2.5538821055088412e-20\n",
            "Progress:  78 w= 1.9999999999566096 loss= 1.395911981720485e-20\n",
            "Progress:  79 w= 1.9999999999679208 loss= 7.629835489260853e-21\n",
            "Progress:  80 w= 1.9999999999762834 loss= 4.1703587348634304e-21\n",
            "Progress:  81 w= 1.999999999982466 loss= 2.2794492685101314e-21\n",
            "Progress:  82 w= 1.9999999999870368 loss= 1.2459146530984002e-21\n",
            "Progress:  83 w= 1.999999999990416 loss= 6.809938252034201e-22\n",
            "Progress:  84 w= 1.9999999999929146 loss= 3.7222634171833075e-22\n",
            "Progress:  85 w= 1.9999999999947617 loss= 2.0345645351347754e-22\n",
            "Progress:  86 w= 1.9999999999961273 loss= 1.111956767993656e-22\n",
            "Progress:  87 w= 1.999999999997137 loss= 6.078024234250996e-23\n",
            "Progress:  88 w= 1.9999999999978835 loss= 3.321867956024464e-23\n",
            "Progress:  89 w= 1.9999999999984353 loss= 1.8155153909015986e-23\n",
            "Progress:  90 w= 1.9999999999988431 loss= 9.924324587996338e-24\n",
            "Progress:  91 w= 1.9999999999991447 loss= 5.4254937562672315e-24\n",
            "Progress:  92 w= 1.9999999999993676 loss= 2.965078402510872e-24\n",
            "Progress:  93 w= 1.9999999999995324 loss= 1.6208041997509026e-24\n",
            "Progress:  94 w= 1.9999999999996543 loss= 8.861543418439488e-25\n",
            "Progress:  95 w= 1.9999999999997444 loss= 4.844903798592123e-25\n",
            "Progress:  96 w= 1.999999999999811 loss= 2.645787049730281e-25\n",
            "Progress:  97 w= 1.9999999999998603 loss= 1.4456574558768205e-25\n",
            "Progress:  98 w= 1.9999999999998967 loss= 7.894303641869682e-26\n",
            "Progress:  99 w= 1.9999999999999236 loss= 4.3314528064842435e-26\n"
          ]
        }
      ],
      "source": [
        "# In this method, we learn the dataset multiple times (called epochs)\n",
        "# Each time, the weight (w) gets updates using the graident decent algorithm based on weights of the previous epoch\n",
        "\n",
        "alpha = 0.01 # Let us set learning rate as 0.01\n",
        "weight_list = []\n",
        "loss_list=[]\n",
        "\n",
        "for epoch in range(100):\n",
        "    total_loss=0\n",
        "    count = 0\n",
        "    for x, y in zip(x_data, y_data):\n",
        "        \n",
        "        #call the forward function to calculate y_pred\n",
        "        ## YOUR CODE STARTS HERE\n",
        "        y_pred = forward(w, x)\n",
        "        ## YOUR CODE ENDS HERE\n",
        "        \n",
        "        #call the gradient function to obtain the grad for the given data-pair and update the weight\n",
        "        ## YOUR CODE STARTS HERE\n",
        "        grad = gradient(x, y, w)\n",
        "        w -= alpha*grad\n",
        "        ## YOUR CODE ENDS HERE\n",
        "        \n",
        "        #call the loss function to obtain the mean_squared_error of the current sample\n",
        "        ## YOUR CODE STARTS HERE\n",
        "        current_loss = loss(y_pred, y)\n",
        "        ## YOUR CODE ENDS HERE\n",
        "        \n",
        "        total_loss+=current_loss\n",
        "        \n",
        "        count += 1\n",
        "    \n",
        "    avg_mse = total_loss / count\n",
        "    print('Progress: ', epoch, 'w=', w, 'loss=', avg_mse)\n",
        "    weight_list.append(w)\n",
        "    loss_list.append(avg_mse) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kzj0DWFkGsW"
      },
      "source": [
        "Calculate $y_{pred}$ for $x=4$ after training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tu1TgI9wkGsW",
        "outputId": "72a65d4c-6ca3-4557-cfb6-b7af720eaafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Y Value for x=4 : 8\n",
            "Predicted Y Value before training :  4.0\n",
            "Predicted Y Value after training :  7.9999999999996945\n"
          ]
        }
      ],
      "source": [
        "y_pred_with_train = forward(w, 4)\n",
        "\n",
        "print(\"Actual Y Value for x=4 : 8\")\n",
        "print(\"Predicted Y Value before training : \" , y_pred_without_train)\n",
        "print(\"Predicted Y Value after training : \" , y_pred_with_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr8Vlk_4kGsX"
      },
      "source": [
        "### Visualize Loss as a function of weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "id": "u0M_TlvgkGsX",
        "outputId": "0ce2de9d-2b6e-44ac-b612-aad0d183ef52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(weight_list, loss_list)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('w')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Task-02.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}