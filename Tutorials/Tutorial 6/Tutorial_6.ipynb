{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrUVXuMSkDQQ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A9EtAGtyTQJ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_AuUCJJkRiD"
      },
      "source": [
        "## Utilising GPU using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERUEzqqakS3e",
        "outputId": "0f572e24-139c-40a2-d351-147393ff5c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# cpu-gpu\n",
        "a = torch.randn((3, 4))\n",
        "print(a.device)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "a = a.to(device)\n",
        "print(a.device)\n",
        "\n",
        "# a more generic code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n474i7A4kjm3",
        "outputId": "ad5054f2-65cc-4515-ce19-834586f6e773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 18 10:58:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W /  70W |    612MiB / 15109MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxjZWEfIkn7X"
      },
      "source": [
        "## Dataset and Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "66a0a59049c141fd909712ef9d2b3207",
            "6d864a28006640bcbe1ad9598da37ea5",
            "c13124d24a8548f1988b4a857437a83f",
            "479754c420364bc39ef907fef68dade8",
            "e97c770d3c124a358016ea1ec7875109",
            "084fabb4537c4f75ad357d5ede1abb86",
            "e8329cf844c040ada4aa63d17ff062e9",
            "d0580a1e8790444d8156b03be0943982",
            "84332f5a2adc43a7ac66af15185e38b4",
            "c15618edf362448da8b436e7ed90d933",
            "715d758644034cdab1805b879faebc9e"
          ]
        },
        "id": "Afh2_n-PTc_U",
        "outputId": "c0a7fb3a-c931-40c2-c20f-d5a8c232f7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66a0a59049c141fd909712ef9d2b3207"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=True, transform=train_transform, download=True)\n",
        "test_dset = torchvision.datasets.CIFAR10(root=\"data/\", train=False, transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwrVIg6BUUKI",
        "outputId": "8ff2481b-0b44-4e04-fdb0-790b97653a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train samples: 50000\n",
            "# of test samples: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train samples: {len(train_dset)}\")\n",
        "print(f\"# of test samples: {len(test_dset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R_RniHmyUgsz"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dset, batch_size=100, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dset, batch_size=100, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GoIkiN8VJXx",
        "outputId": "b52f2787-5f49-49c4-fb00-4264b00c3f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of train batches: 500\n",
            "# of test batches: 100\n"
          ]
        }
      ],
      "source": [
        "print(f\"# of train batches: {len(train_loader)}\")\n",
        "print(f\"# of test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uokKboX4VO02",
        "outputId": "7e0d141f-e498-4b8c-8b1b-74105914072c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample i/o sizes\n",
            "input size: torch.Size([100, 3, 32, 32])\n",
            "output size: torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "print(\"sample i/o sizes\")\n",
        "data = next(iter(train_loader))\n",
        "img, target = data\n",
        "print(f\"input size: {img.shape}\")\n",
        "print(f\"output size: {target.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJjyNdKkr1t"
      },
      "source": [
        "## LeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Usjem5RSVdso"
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.flat = nn.Flatten()\n",
        "    self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "    # TODO: missing input feature size\n",
        "    self.fc1   = nn.Linear(400, 120)\n",
        "    self.fc2   = nn.Linear(120, 84)\n",
        "    # TODO: missing output feature size\n",
        "    self.fc3   = nn.Linear(84, 10)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "  # TODO: add maxpool operation of given kernel size\n",
        "  # https://pytorch.org/docs/stable/nn.functional.html\n",
        "  def pool(self, x, kernel_size=2):\n",
        "    out = F.max_pool2d(x, kernel_size = kernel_size)\n",
        "    return out\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.conv1(x))\n",
        "    out = self.pool(out)\n",
        "    out = self.activ(self.conv2(out))\n",
        "    out = self.pool(out)\n",
        "\n",
        "    # TODO: flatten\n",
        "    out = self.flat(out)\n",
        "    out = self.activ(self.fc1(out))\n",
        "    out = self.activ(self.fc2(out))\n",
        "    out = self.fc3(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJAne7Wfkuvr"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rDgBFjcgXxqC"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules import padding\n",
        "class VGG(nn.Module):\n",
        "  CONFIGS = {\n",
        "      \"vgg11\": [64, \"pool\", 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg13\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, \"pool\", 512, 512, \"pool\", 512, 512, \"pool\"],\n",
        "      \"vgg16\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, \"pool\", 512, 512, 512, \"pool\", 512, 512, 512, \"pool\"],\n",
        "      \"vgg19\": [64, 64, \"pool\", 128, 128, \"pool\", 256, 256, 256, 256, \"pool\", 512, 512, 512, 512, \"pool\", 512, 512, 512, 512, \"pool\"],\n",
        "  }\n",
        "  def __init__(self, cfg):\n",
        "    super(VGG, self).__init__()\n",
        "    # TODO: missing input dimension\n",
        "    self.flat = nn.Flatten()\n",
        "    in_dim = 3\n",
        "    layers = []\n",
        "    for layer in self.CONFIGS[cfg]:\n",
        "        if layer == \"pool\":\n",
        "            # TODO: add maxpool module of given kernel size, stride (here 2 each)\n",
        "            # https://pytorch.org/docs/stable/nn.html\n",
        "            maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            layers.append(maxpool)\n",
        "        else:\n",
        "            # TODO: add sequential module consisting of convolution (kernel size = 3, padding = 1), batchnorm, relu\n",
        "            # https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential\n",
        "            block = nn.Sequential(nn.Conv2d(in_dim, layer, kernel_size = 3, padding = 1),\n",
        "                                  nn.BatchNorm2d(layer),\n",
        "                                  nn.ReLU())\n",
        "            layers.append(block)\n",
        "            in_dim = layer\n",
        "    # TODO: add average pool to collapse spatial dimensions\n",
        "    avgpool = nn.AvgPool2d(kernel_size = 1)\n",
        "    layers.append(avgpool)\n",
        "    self.layers = nn.Sequential(*layers)\n",
        "    # TODO: missing output features\n",
        "    self.fc = nn.Linear(512, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layers(x)\n",
        "    # TODO: flatten\n",
        "    out = self.flat(out)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRtGz0Z_kwJr"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HwEtA8o0bRnz"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_dim, dim, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(dim)\n",
        "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(dim)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "    self.shortcut = nn.Identity()\n",
        "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
        "    if (in_dim != dim or stride != 1):\n",
        "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
        "        self.shortcut = nn.Sequential(nn.Conv2d(in_dim, dim, kernel_size = 1, stride = stride, bias = False),\n",
        "                                      nn.BatchNorm2d(dim))\n",
        "      \n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    # TODO: missing residual connection\n",
        "    out = out + self.shortcut(x)\n",
        "    out = self.activ(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "\n",
        "  def __init__(self, in_dim, dim, stride=1):\n",
        "    super(Bottleneck, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_dim, dim, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(dim)\n",
        "    self.conv2 = nn.Conv2d(dim, dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(dim)\n",
        "    self.conv3 = nn.Conv2d(dim, self.expansion * dim, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(self.expansion*dim)\n",
        "    self.activ = nn.ReLU()\n",
        "\n",
        "    self.shortcut = nn.Identity()\n",
        "    # TODO: missing condition for parameterized shortcut connection (hint: when input and output dimensions don't match - both spatial, feature)\n",
        "    if (in_dim != self.expansion*dim or stride != 1):\n",
        "        # TODO: add sequential module consisting of 1x1 convolution (given stride, bias=False), batchnorm\n",
        "        self.shortcut = nn.Sequential(nn.Conv2d(in_dim, self.expansion*dim, kernel_size = 1, stride = stride, bias = False),\n",
        "                                      nn.BatchNorm2d(self.expansion*dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.activ(self.bn2(self.conv2(out)))\n",
        "    out = self.bn3(self.conv3(out))\n",
        "    # TODO: missing residual connection\n",
        "    out = out + self.shortcut(x)\n",
        "    out = self.activ(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  CONFIGS = {\n",
        "      \"resnet18\": (BasicBlock, [2, 2, 2, 2]),\n",
        "      \"resnet34\": (BasicBlock, [3, 4, 6, 3]),\n",
        "      \"resnet50\": (Bottleneck, [3, 4, 6, 3]),\n",
        "      \"resnet101\": (Bottleneck, [3, 4, 23, 3]),\n",
        "      \"resnet152\": (Bottleneck, [3, 8, 36, 3]),\n",
        "  }\n",
        "  def __init__(self, cfg):\n",
        "    super(ResNet, self).__init__()\n",
        "    block, num_blocks = self.CONFIGS[cfg]\n",
        "    self.in_dim = 64\n",
        "    self.flat = nn.Flatten()\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size = 4)\n",
        "    self.activ = nn.ReLU()\n",
        "    # TODO: missing output features\n",
        "    self.linear = nn.Linear(512*block.expansion, 10)\n",
        "\n",
        "  def _make_layer(self, block, dim, num_blocks, stride):\n",
        "    strides = [stride] + [1]*(num_blocks-1)    \n",
        "    layers = []\n",
        "    for stride in strides: \n",
        "        # TODO: create layers within block\n",
        "        layer = block(self.in_dim, dim, stride)\n",
        "        layers.append(layer)\n",
        "        # TODO: update in_dim based on block output size\n",
        "        self.in_dim = block.expansion * dim\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.activ(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    # TODO: average pool and flatten\n",
        "    out = self.flat(self.avgpool(out))\n",
        "    out = self.linear(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4ywUDe3k0ZQ"
      },
      "source": [
        "## Utility functions (can ignore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iUXIGxAvfdBc"
      },
      "outputs": [],
      "source": [
        "def pbar(p=0, msg=\"\", bar_len=20):\n",
        "    sys.stdout.write(\"\\033[K\")\n",
        "    sys.stdout.write(\"\\x1b[2K\" + \"\\r\")\n",
        "    block = int(round(bar_len * p))\n",
        "    text = \"Progress: [{}] {}% {}\".format(\n",
        "        \"\\x1b[32m\" + \"=\" * (block - 1) + \">\" + \"\\033[0m\" + \"-\" * (bar_len - block),\n",
        "        round(p * 100, 2),\n",
        "        msg,\n",
        "    )\n",
        "    print(text, end=\"\\r\")\n",
        "    if p == 1:\n",
        "        print()\n",
        "\n",
        "\n",
        "class AvgMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.metrics = {}\n",
        "\n",
        "    def add(self, batch_metrics):\n",
        "        if self.metrics == {}:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key] = [value]\n",
        "        else:\n",
        "            for key, value in batch_metrics.items():\n",
        "                self.metrics[key].append(value)\n",
        "\n",
        "    def get(self):\n",
        "        return {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "\n",
        "    def msg(self):\n",
        "        avg_metrics = {key: np.mean(value) for key, value in self.metrics.items()}\n",
        "        return \"\".join([\"[{}] {:.5f} \".format(key, value) for key, value in avg_metrics.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM4qJwaDlBwD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XdwembsSja6-"
      },
      "outputs": [],
      "source": [
        "def train(model, optim, lr_sched=None, epochs=200, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), criterion=None, metric_meter=None, out_dir=\"out/\"):\n",
        "  model.to(device)\n",
        "  best_acc = 0\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    metric_meter.reset()\n",
        "    for indx, (img, target) in enumerate(train_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: missing backward, parameter update\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "      metric_meter.add({\"train loss\": loss.item()})\n",
        "      pbar(indx / len(train_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "\n",
        "    model.eval()\n",
        "    metric_meter.reset()\n",
        "    correct = 0\n",
        "    total = 0 \n",
        "    for indx, (img, target) in enumerate(test_loader):\n",
        "      # TODO: send to device (cpu or gpu)\n",
        "      img = img.to(device)\n",
        "      target = target.to(device)\n",
        "\n",
        "      # TODO: missing forward pass\n",
        "      out = model(img)\n",
        "      loss = criterion(out, target)\n",
        "      # TODO: compute accuracy\n",
        "      _, predicted = torch.max(out.data, 1)\n",
        "      total += target.size(0)\n",
        "      correct += (predicted == target).sum().item()\n",
        "      acc = correct / total\n",
        "\n",
        "      metric_meter.add({\"test loss\": loss.item(), \"test acc\": acc})\n",
        "      pbar(indx / len(test_loader), msg=metric_meter.msg())\n",
        "    pbar(1, msg=metric_meter.msg())\n",
        "    \n",
        "    test_metrics = metric_meter.get()\n",
        "    if test_metrics[\"test acc\"] > best_acc:\n",
        "      print(\n",
        "          \"\\x1b[33m\"\n",
        "          + f\"test acc improved from {round(best_acc, 5)} to {round(test_metrics['test acc'], 5)}\"\n",
        "          + \"\\033[0m\"\n",
        "      )\n",
        "      best_acc = test_metrics['test acc']\n",
        "      torch.save(model.state_dict(), os.path.join(out_dir, \"best.ckpt\"))\n",
        "    lr_sched.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QSyZus3lD7f"
      },
      "source": [
        "## Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1Wy8hIQfiGqS"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model_name=\"lenet\", model_cfg=None, epochs=200):\n",
        "  if model_name == \"lenet\":\n",
        "    model = LeNet()\n",
        "  elif model_name == \"vgg\":\n",
        "    model = VGG(model_cfg)\n",
        "  elif model_name == \"resnet\":\n",
        "    model = ResNet(model_cfg)\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "  optim = torch.optim.Adam(model.parameters()) # torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=5e-4)\n",
        "  lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  metric_meter = AvgMeter()\n",
        "  out_dir = f\"{model_name}_{model_cfg}\"\n",
        "  os.makedirs(out_dir, exist_ok=True)\n",
        "  train(model, optim, lr_sched, epochs=epochs, criterion=criterion, metric_meter=metric_meter, out_dir=out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgYPvSM4jUEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8316ff48-358e-4ae6-aa18-d1a0c19a1ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 429.97416 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1333.02974 [test acc] 0.10266 \n",
            "\u001b[33mtest acc improved from 0 to 0.10266\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 706466603.82603 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 3477.96807 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 3425.46467 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 4368.70942 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5377.07152 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5589.64218 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6119.87598 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5793.97495 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8083.52154 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9110.55767 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7825.68725 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8389.29617 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9839.22195 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9834.78449 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11040.23092 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11265.64806 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9685.21366 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8353.36589 [test acc] 0.10335 \n",
            "\u001b[33mtest acc improved from 0.10266 to 0.10335\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12327.23692 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11584.27005 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11624.56760 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13785.99229 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11327.64941 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12765.14134 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14012.86217 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12795.95173 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13464.73131 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13733.16817 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10547.67222 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12116.66022 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14803.93146 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18566.26881 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14085.98182 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14448.64725 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12270.10474 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11623.57863 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15280.08636 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12463.86647 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12638.65691 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15397.71028 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14480.88137 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15702.61272 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15990.16032 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13371.63681 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12178.88503 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12109.11677 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13672.37170 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15543.01408 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14433.99273 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11040.32837 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15843.77992 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15842.76230 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13584.84342 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14135.13719 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12647.21406 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16757.96145 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16858.64710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15604.80935 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12250.75507 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12565.17698 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12925.39903 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14628.44481 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16461.81834 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18557.58484 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15807.74370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15186.56266 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13817.44386 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11571.55495 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12491.63191 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14536.15741 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16948.62836 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18176.27268 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14566.93686 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13366.72803 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13267.26636 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15975.95808 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15140.68258 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13003.20192 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12902.85571 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16975.83530 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 17544.00806 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17584.70746 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13504.34953 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11152.55220 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13587.08512 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15601.64482 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15856.62125 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17304.14604 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13191.20083 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11267.23337 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12836.67063 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16795.28185 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 18106.82470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16357.58443 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11750.25792 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8639.62907 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15122.00016 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 20035.43521 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14221.00039 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9517.84901 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13288.66932 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15012.52337 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15980.84908 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15309.08951 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14869.79682 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11681.60678 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12329.84883 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14319.56360 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15272.38093 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14865.38652 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15408.37235 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14565.65394 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12457.00608 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11748.79576 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14202.26056 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11991.05914 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15715.89512 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17940.79499 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15137.04293 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15087.62632 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11706.21674 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11229.42037 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15597.11734 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16651.42377 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15875.75738 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13321.82293 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13014.06182 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14513.06596 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14119.67166 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16688.48182 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15988.31393 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12898.14695 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12381.20554 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11077.56796 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14677.72519 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17756.96210 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 17151.70842 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16660.73445 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14301.76782 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13913.71916 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12121.84772 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12635.08578 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13543.48096 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13273.40635 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16093.36321 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18259.41117 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 17687.18100 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14658.39254 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11457.30332 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11806.85030 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13759.31239 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16282.71632 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16713.09470 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15907.10253 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14926.65216 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15295.31345 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10939.23600 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11991.67845 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15925.23894 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15017.09139 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 17089.56208 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14876.97858 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13559.41446 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11739.33546 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12462.85619 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11964.05229 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13942.53747 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14523.33883 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16598.14651 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16769.05222 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13691.68477 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14565.88178 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14431.75862 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12886.49558 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13492.97685 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 19115.92459 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15716.63468 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12705.57968 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13916.17911 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12740.48160 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14384.99297 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13560.89107 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14710.02270 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14875.43157 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10610.59474 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11525.83648 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15202.57739 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15699.08147 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15638.23463 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16526.50526 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15549.31125 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14208.30732 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15062.56604 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12801.86823 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12178.07225 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13293.81776 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16041.44801 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11298.86221 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10109.44009 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10097.01502 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11599.57639 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14775.50472 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 18114.36050 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16352.97927 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14718.36174 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13403.01626 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16078.23506 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 19201.72152 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15124.02184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9983.08382 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8798.69001 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9259.30149 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16031.86308 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18521.76104 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15801.57913 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13940.20736 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12616.32515 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13391.49104 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12368.48071 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13849.08977 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16116.28467 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17767.90281 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15223.56370 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11787.80912 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11108.90125 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12380.84365 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13671.04132 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12996.83308 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16776.43793 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16742.12347 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15299.54088 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14554.65024 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8717.54619 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9834.38426 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13318.58388 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13882.92618 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14020.24506 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16364.21777 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16797.76284 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15115.55690 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15087.07701 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12170.58673 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13716.34029 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12775.63246 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14223.61263 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10787.18521 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10835.06241 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10053.42592 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14744.77669 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14924.83688 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13101.65816 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13341.23043 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13053.12468 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13405.59763 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14791.02343 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14957.88888 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13925.17160 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12330.36866 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12270.23927 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13965.09875 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15274.79588 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14797.40392 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12131.70456 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9932.63250 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12383.38366 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14654.95707 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13504.32710 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13762.19926 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13374.64168 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11599.81324 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12900.29490 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16170.93382 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13713.17894 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12245.03097 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12171.19864 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15192.96056 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14865.98391 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14569.82156 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13180.11908 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13501.92803 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13646.73981 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10635.12839 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11424.03745 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14228.65868 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13424.19820 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14107.22149 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12508.91870 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11372.89687 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11279.09831 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9912.16075 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12024.32116 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12794.01428 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11850.14357 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12881.23168 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13713.93931 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12706.74532 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12948.53400 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13679.18657 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14850.35193 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14887.03103 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13234.34321 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11885.70643 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11301.88491 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9346.77863 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11312.44754 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11369.56240 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11103.88253 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9500.46618 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11941.59840 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14384.69884 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11369.41572 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9433.61636 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11429.71011 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12674.07095 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11862.52146 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10446.65397 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7594.01129 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7278.21258 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8966.53373 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10010.64509 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11495.32729 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13902.25024 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13596.18081 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12796.75030 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13331.18523 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12227.62846 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12284.46602 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11938.95564 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11861.15791 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13199.91562 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13052.90102 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12413.15547 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11476.64771 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8900.81315 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7359.86363 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7435.05119 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9853.33478 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10093.79392 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10062.93587 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10135.07786 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9130.74450 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9061.29233 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9975.90983 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10588.68813 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9557.91729 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8404.81353 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7829.93086 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9236.36529 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10357.74872 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10056.26906 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10174.43775 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9972.55071 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7575.27427 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5422.72113 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5917.10091 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5831.62197 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5647.03814 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6285.98507 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7229.30787 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7814.33104 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7490.52101 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6952.97810 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7294.62039 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8288.57973 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8647.10001 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8332.88979 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6889.55591 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 4926.35012 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 4771.38464 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 4771.10422 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5004.01112 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5176.26735 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5641.24526 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6276.96957 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6678.73833 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6749.60458 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6576.49825 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6475.63166 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6739.36957 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6824.11001 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6520.95146 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6026.85467 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5904.95840 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6003.94369 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6022.57068 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5925.33838 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5883.76267 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5964.11069 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5998.48085 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5975.38478 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5891.52042 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5820.26584 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5848.94365 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5865.81666 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5856.89670 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5850.17478 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5848.17987 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5843.83317 [test acc] 0.10020 \n"
          ]
        }
      ],
      "source": [
        "run_experiment(model_name=\"lenet\", model_cfg = None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(model_name=\"vgg\", model_cfg = 'vgg11')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NxA2WhF7Skca",
        "outputId": "c2e6fefc-adab-4941-cd28-30d47661b01b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1035134855198.74536 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 4372475293193994.00000 [test acc] 0.06144 \n",
            "\u001b[33mtest acc improved from 0 to 0.06144\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 19762096897808712.00000 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 28284972503.04000 [test acc] 0.09879 \n",
            "\u001b[33mtest acc improved from 0.06144 to 0.09879\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 20974925.65659 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 625448930.88000 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1689294.46660 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6843.15382 [test acc] 0.10104 \n",
            "\u001b[33mtest acc improved from 0.09879 to 0.10104\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 560497.96290 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7020.29534 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7682.74088 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7584.17011 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7862.17173 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9231.74879 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9883.40638 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7584.29965 [test acc] 0.10184 \n",
            "\u001b[33mtest acc improved from 0.10104 to 0.10184\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8755.53414 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8730.69251 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11612.07249 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14043.66547 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11645.58282 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12330.23690 [test acc] 0.10266 \n",
            "\u001b[33mtest acc improved from 0.10184 to 0.10266\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10034.41719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14731.79851 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12788.01444 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11894.37400 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13422.44459 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14936.13464 [test acc] 0.10335 \n",
            "\u001b[33mtest acc improved from 0.10266 to 0.10335\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1794573591.19513 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10806.35650 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13973.86601 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12250.97492 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 152241.28117 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12411.53779 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11790.74100 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13601.73495 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13508.61568 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16960.19997 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14835.34511 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15057.39985 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12630.73409 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12155.18687 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14391.10115 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13813.68281 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14096.17324 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13228.22598 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12447.87656 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13722.72861 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15773.78195 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16081.41915 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15263.28643 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7317.34050 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9682.01894 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15441.42128 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16244.88542 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18218.77520 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16189.94432 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13993.89434 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14824.98987 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12367.69098 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13228.48306 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17772.73181 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14300.36954 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11342.51728 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14861.50298 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17584.52372 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14304.46590 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15530.30221 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15166.77389 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15226.35023 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13788.43567 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15749.54770 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15057.60258 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15783.90179 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15126.13540 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12469.07843 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13447.37969 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11471.50693 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15514.41375 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16898.17875 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15634.79506 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15524.68733 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11417.15096 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13311.13021 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16503.35426 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15591.31948 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15230.19188 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17207.51115 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14553.64025 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13506.77664 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14091.19160 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15496.95040 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15796.15783 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11239.22479 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13009.66946 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11802.33299 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14536.54477 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18501.43915 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16878.85797 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13519.59121 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12817.86754 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13619.52504 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16242.51811 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16026.20683 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13685.33977 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11546.27801 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13134.85906 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17158.36157 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16209.99041 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12790.30853 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13815.67033 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16705.82857 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14991.35904 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14336.05429 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14709.27028 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12315.55512 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12379.28172 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17181.57485 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 17481.66601 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13894.37084 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12448.25540 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15512.59837 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15940.48259 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9917.46929 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12088.06447 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14117.63117 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15064.43353 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10634.20554 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13739.00533 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14521.21881 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14784.02609 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16000.72820 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16344.57779 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 19174.84775 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11581.21250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10191.17581 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12617.78861 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16535.62887 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 17967.66926 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14136.36158 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12798.74201 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15681.71208 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16031.26481 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14311.67056 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11964.03352 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12220.46134 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13175.68786 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14274.75876 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15873.53485 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18210.28190 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14469.67584 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13861.39543 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13437.51934 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10480.69704 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13373.94243 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 19389.93817 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 17682.95967 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15016.38546 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13547.19579 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14779.31216 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13416.77537 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12098.16023 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14822.14203 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15385.28796 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14495.88307 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13733.21132 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13225.09648 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14300.42192 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15580.71030 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15563.77215 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15117.55819 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17339.46949 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14201.08264 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9669.72192 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13799.60317 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16335.30368 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13853.44015 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16292.75101 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15371.80124 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14485.73837 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14922.10124 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15299.72102 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14069.11846 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13174.50539 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12230.92224 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13225.92031 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14850.61896 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14878.69885 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16834.86148 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16893.25616 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13910.13336 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10073.04357 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11924.75146 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16480.22246 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15421.93332 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14468.82711 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14706.40151 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17326.85514 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15132.33833 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12639.03871 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12573.12917 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15272.03936 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16617.49445 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16862.55719 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12817.69713 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14823.68349 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12392.75362 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12921.03288 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14499.94533 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17839.45883 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16827.77695 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14944.63576 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13939.36019 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10158.36803 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12204.32811 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16180.34477 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15693.01178 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17643.44576 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12902.88388 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13887.53939 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13822.91499 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14521.91270 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13796.15683 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13967.82539 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15082.64388 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17742.42604 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15376.90356 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11630.78370 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13442.37751 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12525.48754 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13125.06030 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13441.38109 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14493.52366 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11809.45741 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15016.89906 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16398.14440 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14871.08988 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12927.22191 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14184.15581 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13629.65967 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13086.69284 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16623.46930 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13140.36118 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10891.29592 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11599.62164 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15657.20849 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16716.23767 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17488.10138 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15048.96578 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15309.51652 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12942.90495 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13235.93098 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12987.36936 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12401.66774 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13069.79207 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 18238.75925 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16247.34640 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13065.75195 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13055.74414 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11560.87733 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10853.74539 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13858.43775 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14250.99495 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13819.27587 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16628.45581 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17498.41815 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14569.00002 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10882.33697 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9262.93163 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10409.00178 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11322.60628 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12349.89325 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14201.92203 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 17978.46366 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 16553.00790 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13480.32562 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15227.34903 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15875.44545 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12155.17431 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9682.05010 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11558.01241 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13815.76579 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 14916.91134 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12578.08800 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10622.00663 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10617.83631 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12786.44044 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11517.21941 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12782.74570 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 15023.86236 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 15900.62735 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16275.84623 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13602.76364 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12424.95207 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9760.83124 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8936.55225 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11175.69022 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11435.95406 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13383.97681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 16190.53720 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13640.70821 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11526.46278 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11928.65653 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14061.06668 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12952.06799 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12980.71514 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12515.50584 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12133.87896 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12094.05893 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10234.62061 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11086.74187 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 14420.98617 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13812.32909 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12831.58147 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11432.35407 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9502.15322 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10969.78166 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10515.43273 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 11224.34874 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10023.61518 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10710.41166 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13163.76553 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12985.56152 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11593.35266 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9962.65403 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11193.50235 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12371.94159 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12706.50069 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10480.23601 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8970.36085 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8272.82838 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9559.79610 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9477.12753 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7692.59243 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9460.73583 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9958.90748 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12131.49477 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 13451.81503 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 13067.85178 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12881.35425 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12276.96649 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12981.21894 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 12501.08564 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 11148.18739 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10240.27629 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9380.89737 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8859.46851 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8146.72134 [test acc] 0.10335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5960.08612 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 4682.48756 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5884.55903 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7382.49613 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 9086.87195 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 10383.63661 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 10344.73700 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 9966.63887 [test acc] 0.09879 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8403.59820 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6685.81192 [test acc] 0.10104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6291.07724 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6257.32801 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7396.29934 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8395.93122 [test acc] 0.09855 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7864.21927 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7508.97882 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7842.91083 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8061.47749 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8322.48367 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8373.19110 [test acc] 0.10266 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7771.82714 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7260.81086 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7835.15354 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8449.60929 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8897.89473 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 8895.72776 [test acc] 0.09958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 8224.19950 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7821.82099 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7968.33384 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7787.20917 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 7505.02208 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 7115.52081 [test acc] 0.09719 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6901.72400 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6871.75112 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 6534.06740 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 6007.46348 [test acc] 0.09681 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5439.20360 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 5053.45365 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 5015.88120 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 4977.78370 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 4790.31104 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 4518.96661 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 4215.33518 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 3853.96851 [test acc] 0.10020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 3740.90265 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 3605.22403 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 3488.15724 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 3349.30362 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 3269.42948 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 3180.05624 [test acc] 0.10184 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 3153.17623 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 3123.85825 [test acc] 0.10184 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment(model_name=\"resnet\", model_cfg = 'resnet18')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bqjBaY85YgnG",
        "outputId": "3201c9fc-d6dc-4554-dacd-c23780133045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.95073 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.97173 [test acc] 0.10687 \n",
            "\u001b[33mtest acc improved from 0 to 0.10687\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.33977 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 12.81595 [test acc] 0.12732 \n",
            "\u001b[33mtest acc improved from 0.10687 to 0.12732\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.33831 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.61409 [test acc] 0.15510 \n",
            "\u001b[33mtest acc improved from 0.12732 to 0.1551\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.21546 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.23025 [test acc] 0.18900 \n",
            "\u001b[33mtest acc improved from 0.1551 to 0.189\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.15871 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.44813 [test acc] 0.16889 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.14407 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.13894 [test acc] 0.17942 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.12338 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.16099 [test acc] 0.19026 \n",
            "\u001b[33mtest acc improved from 0.189 to 0.19026\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.10973 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.06680 [test acc] 0.16594 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.08948 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.22770 [test acc] 0.16841 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.08734 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.08613 [test acc] 0.17859 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.07910 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.13092 [test acc] 0.20319 \n",
            "\u001b[33mtest acc improved from 0.19026 to 0.20319\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.09659 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.06248 [test acc] 0.19453 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.08027 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.09457 [test acc] 0.19304 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.07029 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.17657 [test acc] 0.16833 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.04877 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.05539 [test acc] 0.20259 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.05990 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.11895 [test acc] 0.17554 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.05175 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.05896 [test acc] 0.21355 \n",
            "\u001b[33mtest acc improved from 0.20319 to 0.21355\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.04282 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.15552 [test acc] 0.20492 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.01906 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.01627 [test acc] 0.18740 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.01227 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.02657 [test acc] 0.20025 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.03885 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.04708 [test acc] 0.16635 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.02348 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.02747 [test acc] 0.18630 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.00724 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.07567 [test acc] 0.18861 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.01172 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.03792 [test acc] 0.19253 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.01116 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.03692 [test acc] 0.18682 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.99114 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.06441 [test acc] 0.19378 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.99488 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.01221 [test acc] 0.21106 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.01024 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.04489 [test acc] 0.20103 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.99413 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.94931 [test acc] 0.21633 \n",
            "\u001b[33mtest acc improved from 0.21355 to 0.21633\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97957 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.96304 [test acc] 0.17956 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.98687 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.94493 [test acc] 0.21139 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.98237 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.00304 [test acc] 0.19668 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97793 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.96474 [test acc] 0.21019 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.98541 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.94006 [test acc] 0.19506 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96288 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.94420 [test acc] 0.21323 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97677 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.98295 [test acc] 0.20639 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97431 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.95944 [test acc] 0.17586 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.99012 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.00204 [test acc] 0.19958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.98687 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.98639 [test acc] 0.19389 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.00523 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.93006 [test acc] 0.20874 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.00122 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.01803 [test acc] 0.19656 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.00383 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.97522 [test acc] 0.18971 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.99391 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.93998 [test acc] 0.21431 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.01637 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.98798 [test acc] 0.21071 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97854 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.00417 [test acc] 0.19656 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 2.01371 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.96497 [test acc] 0.19264 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97964 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.96303 [test acc] 0.19651 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.98697 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.03112 [test acc] 0.19599 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97972 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.02217 [test acc] 0.19772 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96438 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.93277 [test acc] 0.21487 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.97138 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.01067 [test acc] 0.19430 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96518 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.99941 [test acc] 0.21734 \n",
            "\u001b[33mtest acc improved from 0.21633 to 0.21734\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96554 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.01174 [test acc] 0.20691 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96140 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.97149 [test acc] 0.22127 \n",
            "\u001b[33mtest acc improved from 0.21734 to 0.22127\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.95479 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.03256 [test acc] 0.21292 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.94916 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.00092 [test acc] 0.22680 \n",
            "\u001b[33mtest acc improved from 0.22127 to 0.2268\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96745 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.92455 [test acc] 0.18647 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96895 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.94661 [test acc] 0.19884 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.95112 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.93415 [test acc] 0.20247 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96493 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.91066 [test acc] 0.21689 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.94821 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.92361 [test acc] 0.20001 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.94452 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.90857 [test acc] 0.22933 \n",
            "\u001b[33mtest acc improved from 0.2268 to 0.22933\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.95501 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.90061 [test acc] 0.21736 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.96225 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.91667 [test acc] 0.18800 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.94966 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.90656 [test acc] 0.22593 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.95349 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.90093 [test acc] 0.20623 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.94481 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.91192 [test acc] 0.20641 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.93863 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.88739 [test acc] 0.22020 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.93589 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.88625 [test acc] 0.17687 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.93233 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.89571 [test acc] 0.21259 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.93250 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.90130 [test acc] 0.20904 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.93509 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.91017 [test acc] 0.20291 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.93295 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.92232 [test acc] 0.23147 \n",
            "\u001b[33mtest acc improved from 0.22933 to 0.23147\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.92858 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.88801 [test acc] 0.19443 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.92566 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.90852 [test acc] 0.20942 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.91959 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.90522 [test acc] 0.22048 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.92658 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.96266 [test acc] 0.19899 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.92228 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.99648 [test acc] 0.21135 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.93240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.88746 [test acc] 0.22773 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.92078 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.87773 [test acc] 0.20733 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.92515 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.88467 [test acc] 0.23271 \n",
            "\u001b[33mtest acc improved from 0.23147 to 0.23271\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90927 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.87758 [test acc] 0.21487 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.91783 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.87659 [test acc] 0.21543 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90277 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.89445 [test acc] 0.22024 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90992 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.88252 [test acc] 0.20899 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90666 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.89142 [test acc] 0.21580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90934 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.91676 [test acc] 0.21442 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.91246 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.93197 [test acc] 0.20001 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90861 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.98690 [test acc] 0.21706 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90524 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.96904 [test acc] 0.21708 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90653 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.89696 [test acc] 0.21304 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89621 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.89354 [test acc] 0.23740 \n",
            "\u001b[33mtest acc improved from 0.23271 to 0.2374\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90289 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.87972 [test acc] 0.20675 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89919 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.88769 [test acc] 0.23448 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90772 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.87894 [test acc] 0.20843 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90585 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.91133 [test acc] 0.20747 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.90267 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.12181 [test acc] 0.22704 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89429 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 2.09859 [test acc] 0.20482 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89179 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.89017 [test acc] 0.22357 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89133 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.87349 [test acc] 0.21585 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.88709 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86609 [test acc] 0.21247 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89459 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86518 [test acc] 0.20219 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.88214 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86744 [test acc] 0.23720 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89601 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86466 [test acc] 0.23612 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87735 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86590 [test acc] 0.20189 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.88665 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.85800 [test acc] 0.21592 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87547 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86378 [test acc] 0.23946 \n",
            "\u001b[33mtest acc improved from 0.2374 to 0.23946\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.89109 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.84951 [test acc] 0.22374 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.86919 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.85267 [test acc] 0.20792 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87626 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.84476 [test acc] 0.22259 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87227 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.85708 [test acc] 0.23952 \n",
            "\u001b[33mtest acc improved from 0.23946 to 0.23952\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87693 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86218 [test acc] 0.22822 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87262 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.86097 [test acc] 0.20771 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87404 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.85349 [test acc] 0.21753 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.86896 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.85000 [test acc] 0.22167 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87307 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.84076 [test acc] 0.21312 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.86145 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.84649 [test acc] 0.23968 \n",
            "\u001b[33mtest acc improved from 0.23952 to 0.23968\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.87146 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83867 [test acc] 0.23059 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85903 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.84054 [test acc] 0.21479 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.86291 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83189 [test acc] 0.23718 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85742 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83859 [test acc] 0.22985 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.86064 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83676 [test acc] 0.24164 \n",
            "\u001b[33mtest acc improved from 0.23968 to 0.24164\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85644 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83557 [test acc] 0.23082 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85974 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83715 [test acc] 0.23542 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85775 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.84027 [test acc] 0.22849 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85708 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83920 [test acc] 0.23857 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85861 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83654 [test acc] 0.22934 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85514 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83111 [test acc] 0.23378 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85872 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83115 [test acc] 0.24393 \n",
            "\u001b[33mtest acc improved from 0.24164 to 0.24393\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85222 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83802 [test acc] 0.23624 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85431 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82956 [test acc] 0.23974 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85100 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83166 [test acc] 0.23042 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85347 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83034 [test acc] 0.24239 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85109 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82951 [test acc] 0.23354 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85085 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82998 [test acc] 0.22995 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84892 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82800 [test acc] 0.25098 \n",
            "\u001b[33mtest acc improved from 0.24393 to 0.25098\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85173 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82806 [test acc] 0.23011 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84998 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83235 [test acc] 0.23954 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85197 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83321 [test acc] 0.23775 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85158 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83174 [test acc] 0.23334 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85082 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82621 [test acc] 0.24158 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84958 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.83154 [test acc] 0.23781 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84796 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82722 [test acc] 0.23244 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84935 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82809 [test acc] 0.24298 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84812 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82693 [test acc] 0.23354 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84584 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82921 [test acc] 0.24712 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84733 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82717 [test acc] 0.23304 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84746 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82878 [test acc] 0.25478 \n",
            "\u001b[33mtest acc improved from 0.25098 to 0.25478\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.85070 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82763 [test acc] 0.23155 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84884 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82245 [test acc] 0.24335 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84580 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82327 [test acc] 0.23536 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84643 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82180 [test acc] 0.24827 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84558 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82184 [test acc] 0.24412 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84476 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82294 [test acc] 0.24496 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84356 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82542 [test acc] 0.23931 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84513 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82381 [test acc] 0.24555 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84376 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.81929 [test acc] 0.23769 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84039 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82054 [test acc] 0.24645 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84347 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82058 [test acc] 0.25540 \n",
            "\u001b[33mtest acc improved from 0.25478 to 0.2554\u001b[0m\n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84253 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82242 [test acc] 0.23625 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84068 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82016 [test acc] 0.23754 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84366 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82047 [test acc] 0.25258 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84037 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.81893 [test acc] 0.25496 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84200 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.81948 [test acc] 0.24217 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84178 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82333 [test acc] 0.23240 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.83899 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.82058 [test acc] 0.24157 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.83968 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.81882 [test acc] 0.24884 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [train loss] 1.84159 \n",
            "Progress: [\u001b[32m===================>\u001b[0m] 100% [test loss] 1.81940 [test acc] 0.25463 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HBcgGTHlQqx"
      },
      "source": [
        "## Questions\n",
        "- Train and report test set metrics on three model types - LeNet, VGG, ResNet. \n",
        "- Which model performs the best and why?\n",
        "- Which model performs the worst and why?\n",
        "- BONUS (extra marks): Modify the LeNet model's convolution layers and compare performance against number of layers (depth), number of nodes per layer (width). (Require atleast 3 data points each for width and depth). Feel free to reduce the number of epochs to obtain results quickly. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ResNet models seems to perform the best because of the presence of residual connections that allow the gradients to flow through it. This allows us to train more deeper networks. The LeNet model performs the worst. This might be because of its relatively simpler architecture.  "
      ],
      "metadata": {
        "id": "cEBgOEro8Q_7"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "66a0a59049c141fd909712ef9d2b3207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d864a28006640bcbe1ad9598da37ea5",
              "IPY_MODEL_c13124d24a8548f1988b4a857437a83f",
              "IPY_MODEL_479754c420364bc39ef907fef68dade8"
            ],
            "layout": "IPY_MODEL_e97c770d3c124a358016ea1ec7875109"
          }
        },
        "6d864a28006640bcbe1ad9598da37ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_084fabb4537c4f75ad357d5ede1abb86",
            "placeholder": "​",
            "style": "IPY_MODEL_e8329cf844c040ada4aa63d17ff062e9",
            "value": "100%"
          }
        },
        "c13124d24a8548f1988b4a857437a83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0580a1e8790444d8156b03be0943982",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84332f5a2adc43a7ac66af15185e38b4",
            "value": 170498071
          }
        },
        "479754c420364bc39ef907fef68dade8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15618edf362448da8b436e7ed90d933",
            "placeholder": "​",
            "style": "IPY_MODEL_715d758644034cdab1805b879faebc9e",
            "value": " 170498071/170498071 [00:03&lt;00:00, 56645726.47it/s]"
          }
        },
        "e97c770d3c124a358016ea1ec7875109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "084fabb4537c4f75ad357d5ede1abb86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8329cf844c040ada4aa63d17ff062e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0580a1e8790444d8156b03be0943982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84332f5a2adc43a7ac66af15185e38b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c15618edf362448da8b436e7ed90d933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715d758644034cdab1805b879faebc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}